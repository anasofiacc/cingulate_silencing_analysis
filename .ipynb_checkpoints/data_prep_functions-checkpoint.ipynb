{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='steelblue'> Functions for optogenetics position and performance analysis - data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions used in latency calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pruned_position_and_cp_rois_all_rats_in_path(path):\n",
    "\n",
    "    '''\n",
    "    Collect the pruned timestamped position and CP rois from all rats in the given path.\n",
    "    Returns two dataframes: (1) Timestamped position data of all rats; (2) CP ROI measures of all rats\n",
    "    '''\n",
    "\n",
    "    data_list = []\n",
    "    rois_list = []\n",
    "    \n",
    "    for a,b,c in os.walk(path):   \n",
    "        data_list = get_data_given_string_to_match(a,b,c, 'pruned', data_list)\n",
    "        rois_list = get_data_given_string_to_match(a,b,c, 'cp_rois_converted', rois_list)\n",
    "        \n",
    "    data = pd.concat(data_list)\n",
    "    rois = pd.concat(rois_list)\n",
    "    \n",
    "    return data, rois\n",
    "\n",
    "def get_data_given_string_to_match(a, b, c, string_to_match, data_list):\n",
    "    \n",
    "    filename = [i for i in c if string_to_match in i] \n",
    "\n",
    "    if filename: \n",
    "\n",
    "        path = os.path.join(a, filename[0])\n",
    "        rat_data = pd.read_csv(path, header=0, index_col=0)   \n",
    "        rat_code = re.search(r\"_(\\w+\\d+)\",a).group(1)        \n",
    "        group_code = re.search(r\"([A-Z]+)\",rat_code).group(1)  \n",
    "                       \n",
    "        rat_data['rat'] = rat_code\n",
    "        rat_data['group'] = group_code  \n",
    "        data_list.append(rat_data)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "def drop_after_cp_entry(group, roi_session):\n",
    "        \n",
    "    xlim =  roi_session['x'].iloc[0]\n",
    "    ylim1 = roi_session['ylim1'].iloc[0]\n",
    "    ylim2 = roi_session['ylim2'].iloc[0]    \n",
    "    mask = (group['x']< xlim) & group['y'].between(ylim1, ylim2)\n",
    "    group = group[mask]\n",
    "       \n",
    "    return group\n",
    "\n",
    "def drop_outside_cp(group, roi_session):\n",
    "    \n",
    "    xlim1 =  roi_session['xlim1'].iloc[0]\n",
    "    xlim2 = roi_session['xlim2'].iloc[0]\n",
    "    ylim1 = roi_session['ylim1'].iloc[0]\n",
    "    ylim2 = roi_session['ylim2'].iloc[0] \n",
    "    \n",
    "    mask = (group['x'].between(xlim1, xlim2) & group['y'].between(ylim1, ylim2))\n",
    "    group = group[mask] \n",
    "            \n",
    "    return group\n",
    "    \n",
    "def discard_data_given_roi(group, roi, to_keep):\n",
    "    \n",
    "    session = group['session'].iloc[0]\n",
    "    rat = group['rat'].iloc[0]    \n",
    "    mask = (roi['session'].str.contains(session[0:15], regex=False)) & (roi['rat'] == rat)    \n",
    "    roi_session = roi[mask]\n",
    "\n",
    "    if to_keep=='before cp entry':\n",
    "        group = group.groupby(['run_nr']).apply(drop_after_cp_entry, roi_session)\n",
    "    elif to_keep=='inside cp':\n",
    "        group = group.groupby(['run_nr']).apply(drop_outside_cp, roi_session)\n",
    "\n",
    "    return group\n",
    "\n",
    "def calculate_quantiles(df, cols_to_group, col_to_calc):\n",
    "    \n",
    "    quantiles = df.groupby(cols_to_group)[col_to_calc].describe(\n",
    "    percentiles = [.1, .2, .3, .4, .5, .6, .7, .8, .9])    \n",
    "    # Keep only the quantiles\n",
    "    quantiles = quantiles.drop(['count', 'mean', 'std', 'min', 'max'], axis=1)\n",
    "    # Rearrange quantiles\n",
    "    level_name = 'level_'+str(len(cols_to_group))\n",
    "    quantiles = quantiles.stack().reset_index().rename(columns={level_name:'quantile', 0:'time'})\n",
    "    \n",
    "    return quantiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get crossing timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_crossing_timestamps_for_runs_in_df(df, cp_rois):\n",
    "    \n",
    "    roi_before_cp = get_roi_before_cp(cp_rois)\n",
    "    cp_square = get_cp_square_limits_from_rois(cp_rois)    \n",
    "    \n",
    "    # Keep only data until entering CP \n",
    "    runs_before_cp_entry = df.groupby(['session', 'rat']).apply(\n",
    "        discard_data_given_roi, \n",
    "        roi_before_cp, \n",
    "        'before cp entry'\n",
    "    )\n",
    "    runs_inside_cp = df.groupby(['session', 'rat']).apply(\n",
    "        discard_data_given_roi, \n",
    "        cp_square, \n",
    "        'inside cp'\n",
    "    ) \n",
    "  \n",
    "    # Rearrange the dataframes\n",
    "    runs_before_cp_entry = runs_before_cp_entry.reset_index(drop=True)    \n",
    "    runs_inside_cp = runs_inside_cp.reset_index(drop=True)  \n",
    "    \n",
    "    # Collect crossing points in maze for each run\n",
    "    start = runs_before_cp_entry.groupby(['session', 'rat', 'run_nr']).nth(0).reset_index()\n",
    "    cp_entry = runs_before_cp_entry.groupby(['session', 'rat', 'run_nr']).last().reset_index()\n",
    "    cp_exit = runs_inside_cp.groupby(['session','rat','run_nr']).last().reset_index()\n",
    "    \n",
    "    #Create a new df with the timestamps of each crossing\n",
    "    test_runs = start.rename(columns={'timestamp':'start_timestamp'}).drop(['x', 'y', 'x_diff'], axis=1)\n",
    "    test_runs['cp_entry_timestamp'] = cp_entry['timestamp']\n",
    "    cp_exit = cp_exit.rename(columns={'timestamp':'cp_exit_timestamp'})\n",
    "    cp_exit = cp_exit.drop(['x', 'y', 'x_diff', 'stim_condition', 'run_type','rat', 'outcome', 'group'], axis=1)\n",
    "\n",
    "    test_runs = test_runs.merge(cp_exit, how='inner', on=['session', 'run_nr'])\n",
    "    \n",
    "    #test_runs = pd.concat([test_runs, cp_entry, cp_exit]).reset_index()\n",
    "    #test_runs['cp_entry_timestamp'] = cp_entry['timestamp']\n",
    "    #test_runs['cp_exit_timestamp'] = cp_exit['timestamp']\n",
    "       \n",
    "    #Plot data until CP (green) over all data (in orange)\n",
    "    #plt.Figure(figsize=(8,4))\n",
    "    #sns.set(style='white', context='talk')\n",
    "    \n",
    "    #import random\n",
    "    #sample_session=random.choice(df['session'].unique())\n",
    "\n",
    "    #sample_raw = df[df['session']==sample_session]\n",
    "    #sample_to_cp = runs_before_cp_entry[runs_before_cp_entry['session']==sample_session]\n",
    "    #sample_inside_cp = runs_inside_cp[runs_inside_cp['session']==sample_session]\n",
    "    #sample_cp_entry = cp_entry[cp_entry['session']==sample_session]\n",
    "    #sample_cp_exit = cp_exit[cp_exit['session']==sample_session]\n",
    "\n",
    "    #sns.scatterplot(data=sample_raw, x='x', y='y', color='gray')\n",
    "    #sns.scatterplot(data=sample_to_cp, x='x', y='y', color='green')\n",
    "    #sns.scatterplot(data=sample_inside_cp, x='x', y='y', color='orange')\n",
    "     \n",
    "    #sns.scatterplot(data=sample_cp_entry, x='x', y='y', color='red')\n",
    "    #sns.scatterplot(data=sample_cp_exit, x='x', y='y', color='blue' )\n",
    "    #sns.despine()      \n",
    "    \n",
    "    return test_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions used in performance calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def remove_single_samples_and_tests(df):\n",
    "    \n",
    "    \n",
    "    Remove trials with only a single sample or single test. They cannot be used to computed performances\n",
    "    \n",
    "    \n",
    "    removed_samples = 0\n",
    "    removed_tests = 0\n",
    "    df = df.reset_index(drop=True)\n",
    "    sample_indices = df.index[df['run_type']=='S'].tolist()\n",
    "    test_indices = df.index[df['run_type'] == 'T'].tolist()\n",
    "    \n",
    "    for i in sample_indices:\n",
    "        prev_i = i-1\n",
    "        if prev_i >=0 and df.loc[prev_i, 'run_type'] =='S':\n",
    "            df.loc[prev_i, 'run_type'] = np.NaN\n",
    "            removed_samples +=1\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    for t in test_indices:\n",
    "        next_t = t+1\n",
    "        if next_t <len(df) and df.loc[next_t, 'run_type'] == 'T':\n",
    "            df.loc[next_t, 'run_type'] = np.NaN\n",
    "            removed_tests +=1\n",
    "            \n",
    "    print('removed unpaired samples:'+str(removed_samples), 'removed unpaired tests: '+str(removed_tests))\n",
    "    return df    '''  \n",
    "\n",
    "def calc_performance_in_group(group):\n",
    "    \n",
    "    '''\n",
    "    Calculate the performance for a given group (GroupBy object)\n",
    "    '''\n",
    "\n",
    "    group = group.dropna()\n",
    "    \n",
    "    n_correct_trials = len(group[group['outcome'] == 1])\n",
    "    n_total_trials = len(group)    \n",
    "    group_performance = (n_correct_trials / n_total_trials)*100\n",
    "    \n",
    "    return group_performance\n",
    "\n",
    "def add_condition_trial_nr(group):\n",
    "    \n",
    "    '''\n",
    "    Add a condition trial number column to each group\n",
    "    '''\n",
    "    \n",
    "    group['cond_trial_nr'] = range(1, len(group)+1)\n",
    "    \n",
    "    return group\n",
    "\n",
    "def calculate_performance_given_ntrials(group, group_label, N):\n",
    "       \n",
    "    '''\n",
    "    \n",
    "    Calculate the performance across the stim protocol. Group the trials by rat and stimulation condition. \n",
    "    Then, for each group, groupby again by the number of rows (df.index / N). For each, count the total \n",
    "    number of trials and sum the correct trials (df['outcome'] ==1). Store each type of information into \n",
    "    two dataframes ('sums' and 'total') and divide, thus calculating the partitioned performance. \n",
    "    These will be labeled with the corresponding rat name, experimental group and stimulation condition. \n",
    "    All these dataframes will be concatenated into one.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df = group.get_group(group_label)\n",
    "    df.index = range(len(df))\n",
    "    \n",
    "    # Divide the number of rows in each group (rat x stim) by N. \n",
    "    # Then either sum the correct trials (outcome==1) or count the total number of trials\n",
    "    sums = df['outcome'].groupby(df.index//N).sum()\n",
    "    total = df['outcome'].groupby(df.index//N).count()\n",
    "    \n",
    "    # Calculate partitioned performance by dividing the \"sums\" and \"total\" dataframes\n",
    "    # Attirbute the rat  group and condition label to each performance in the new par_perf dataframe\n",
    "    \n",
    "    par_perf = ((sums/total)*100).to_frame()\n",
    "    par_perf['group'] = group_label[0]\n",
    "    par_perf['rat'] = group_label[1] \n",
    "    par_perf['stim']= group_label[2]\n",
    "  \n",
    "    return par_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot quantile curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quantile_curves_within_condition(df):\n",
    "    \n",
    "    '''Plot the quantile curves for each stimulation condition, comparing each group'''\n",
    "\n",
    "    sns.set(style='white', context='poster')\n",
    "    g = sns.relplot(\n",
    "        data=df, kind='line',\n",
    "        x='quantile', y='time', hue='group',\n",
    "        markers=['o', 'o'], style='group', \n",
    "        palette=['navy', 'green'],\n",
    "        col='stim_condition', height=5, aspect=1.1, \n",
    "        legend=False   \n",
    "    )\n",
    "    g.set_xticklabels(labels=quantiles['quantile'].unique(), rotation=45)\n",
    "    \n",
    "    axes = g.axes.flatten()\n",
    "    axes[0].set_title(\"No Illumination\")\n",
    "    axes[1].set_title(\"Illumination\")   \n",
    "    plt.legend(['NpHR-', 'NpHR+'], frameon=False, bbox_to_anchor=(1.5,1.2))\n",
    "    sns.despine()\n",
    "    \n",
    "def plot_quantile_curves_within_group(df):\n",
    "\n",
    "    '''Plot the quantile curves for each stimulation condition, comparing each group'''\n",
    "    \n",
    "    sns.set(style='white', context='poster')\n",
    "    g = sns.relplot(\n",
    "        data=df, kind='line', x='quantile', y='time',hue='stim_condition',\n",
    "        col='group', col_wrap=2,height=5, aspect=1.1,\n",
    "        markers=['o', 'o'], style='stim_condition', palette=['black', 'orangered'], \n",
    "        legend=False \n",
    "    )\n",
    "    g.set_xticklabels(labels=quantiles['quantile'].unique(), rotation=45)\n",
    "\n",
    "    axes = g.axes.flatten()\n",
    "    axes[0].set_title(\"NpHR- group\")\n",
    "    axes[1].set_title(\"NpHR+ group\")\n",
    "    plt.legend(['No illumination', 'Illumination'], \n",
    "               frameon=False, bbox_to_anchor=(1.1,1))\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time distributions plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latency_distributions (test_runs, xlim):\n",
    "    \n",
    "    '''\n",
    "    Similar to the subplots but all combined into one plot\n",
    "    '''\n",
    "    fig, axes = plt.subplots(2,1, figsize=(5,8), sharex=True, dpi=300)\n",
    "    sns.set(style='white', context='talk')\n",
    "    plt.suptitle('Latency to choice point entry distributions')\n",
    "\n",
    "    #Stripplots\n",
    "    g = sns.stripplot(ax=axes[0], \n",
    "                      data=test_runs, x='latency_to_cp_entry', y='group', hue='stim_condition',\n",
    "                      hue_order=['0','3'], palette=['black', 'orangered'], \n",
    "                      s=1.5, alpha=.5, jitter=.25, dodge=True)\n",
    "    g.set(yticklabels=['NpHR+', 'NpHR-'], ylabel='Group', xlabel='')\n",
    "    g.legend_.remove()\n",
    "     \n",
    "    # Kernel density plots\n",
    "\n",
    "    b = sns.kdeplot(ax=axes[1], \n",
    "                data=test_runs[test_runs['group'] == 'CTRL'],\n",
    "                x='latency_to_cp_entry', \n",
    "                hue='stim_condition', hue_order=['0', '3'],\n",
    "                palette=['black', 'orangered'], linestyle='dotted')\n",
    "    \n",
    "    sns.kdeplot(ax=axes[1], \n",
    "                data=test_runs[test_runs['group'] == 'NPHR'], \n",
    "                x='latency_to_cp_entry', \n",
    "                hue='stim_condition', hue_order=['0', '3'],\n",
    "                palette=['black', 'orangered'], linestyle='solid')\n",
    "    \n",
    "    b.set(xlim=xlim, ylim=[0, .1], xlabel='seconds')\n",
    "    sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def subplot_latency_distributions_within_conditions(test_runs, xlim, ylim):\n",
    "    \n",
    "    '''\n",
    "    Creates a 4x4 plot grid comparing the latency distributions within illumination condition\n",
    "    (no illumination vs. illumination).\n",
    "    On the top row, it plots the distribution of the latencies between 0 and 60 seconds Below, it plots the kernel density \n",
    "    function (Gaussian) for the latencies on top. Each column contains the data of each illumination condition'''\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for condition in test_runs['stim_condition'].unique():\n",
    "        condition_df =  test_runs[test_runs['stim_condition']==condition]\n",
    "        dfs.append(condition_df)\n",
    "\n",
    "    fig, axes = plt.subplots(2,2, figsize=(10,8), sharex=True, dpi=300)\n",
    "    sns.set(style='white', context='talk')\n",
    "    plt.suptitle('Latency to choice point entry distributions')\n",
    "\n",
    "    colors = ['green', 'navy']\n",
    "    groups = ['NPHR', 'CTRL']\n",
    "    titles = ['No illumination', 'Illumination']\n",
    "\n",
    "    for j, df, title in zip(range(2), dfs, titles):\n",
    "        \n",
    "        #Stripplots\n",
    "        sns.stripplot(ax=axes[0, j], data=df, x='latency_to_cp_entry', y='group', \n",
    "                      palette=colors, s=1.4,\n",
    "                     jitter=.25) \n",
    "        #Kde plots\n",
    "        for color, group in zip(colors, groups):\n",
    "\n",
    "             sns.kdeplot(ax=axes[1,j], data=df[df['group'] == group], x='latency_to_cp_entry', c=color)\n",
    "\n",
    "        axes[1,j].set(xlabel='Latency (s)', xlim=[0,30], ylim=ylim)\n",
    "        axes[0,j].set(title = title, xlim=xlim)\n",
    "\n",
    "        axes[0,1].set(ylabel='', yticklabels='', xlabel='', xlim=xlim)\n",
    "        axes[0,0].set(ylabel='Group', yticklabels=['NpHR+', 'NpHR-'], xlabel=' ', xlim=xlim)\n",
    "\n",
    "        sns.despine()\n",
    "      \n",
    "    \n",
    "def subplot_latency_distributions_within_groups(test_runs, conditions, xlim, ylim):\n",
    "    \n",
    "    # Conditions is a str list of the conditions to plot (no vs. test or no vs. sample)\n",
    "    ctrl = test_runs[test_runs['group']=='CTRL']\n",
    "    nphr = test_runs[test_runs['group']=='NPHR']\n",
    "    dfs = [ctrl, nphr]\n",
    "\n",
    "    fig, axes = plt.subplots(2,2, figsize=(10,8), sharex=True, dpi=300)\n",
    "    sns.set(style='white', context='talk')\n",
    "    plt.suptitle('Latency to choice point entry distributions')\n",
    "\n",
    "    colors = ['black','orangered']\n",
    "    titles = ['NpHR-', 'NpHR+']\n",
    "\n",
    "    for j, df, title in zip(range(2), dfs, titles):\n",
    "        \n",
    "        #Stripplot\n",
    "        sns.stripplot(ax=axes[0, j], data=df, x='latency_to_cp_entry', y='stim_condition', \n",
    "                      palette=colors, s=1.4, jitter=.25) \n",
    "        #Kde plots\n",
    "        for color, condition in zip(colors, conditions):\n",
    "            sns.kdeplot(ax=axes[1,j],\n",
    "                        data=df[df['stim_condition'] == condition], \n",
    "                        x='latency_to_cp_entry', c=color)   \n",
    "\n",
    "        axes[0,j].set(title=title, xlabel='', ylabel='', yticklabels='', xlim=xlim)\n",
    "        axes[0,0].set(ylabel='Condition', yticklabels=['No illumination', 'Illumination'], xlim=xlim)\n",
    "        axes[1,j].set(xlabel='Latency (s)', xlim=xlim, ylim=ylim)\n",
    "      \n",
    "    sns.despine()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get maze limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cp_square_limits_from_rois(df):\n",
    "    '''\n",
    "    Create the CP square limits using the real video CP limits. It will add 10 cm to compensate for light\n",
    "    detection ouside the real limits, since the position tracking light is attached to the patch and not the rat.\n",
    "    10 cm were chosen upon validation of the position data and limits\n",
    "    '''\n",
    "    df2 = df.copy()\n",
    "    df2.rename(columns={'y':'ylim1', 'x':'xlim1'}, inplace=True)\n",
    "    \n",
    "    df2['ylim2'] = df2['ylim1']+df2['height']+10\n",
    "    df2['ylim1'] -=10\n",
    "\n",
    "    df2['xlim2'] = df2['xlim1']+df2['width']+10\n",
    "    df2['xlim1'] -= 10\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_before_cp(df):\n",
    "     \n",
    "    '''\n",
    "    Get the limits of the maze before reaching the CP.\n",
    "    '''  \n",
    "    df2 = df.copy()\n",
    "    df2['ylim1'] = df2['y']-10\n",
    "    df2['ylim2'] = df2['y']+df2['height']+10\n",
    "    df2['x']-=10\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
